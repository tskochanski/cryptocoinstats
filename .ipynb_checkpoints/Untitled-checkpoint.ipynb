{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43552\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.usclimatedata.com/climate/united-states/us')\n",
    "print(len(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Climate United States - Normals and averages</title>\n",
      "Climate United States - Normals and averages\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(r.text)\n",
    "print(soup.title)\n",
    "print(soup.title.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"selection_title\">Select a state by name</p>\n",
      "Select a state by name\n",
      "<a class=\"navbar-brand\" href=\"/\" title=\"Temperature - Precipitation - Sunshine - Snowfall\"><img alt=\"Temperature - Precipitation - Sunshine - Snowfall\" data-src=\"https://www.usclimatedata.com/assets/images/us-climate-data.png\" height=\"34\" src=\"https://www.usclimatedata.com/assets/images/us-climate-data.png\" srcset=\"https://www.usclimatedata.com/assets/images/us-climate-data.png 1x, https://www.usclimatedata.com/assets/images/us-climate-data-2.png 2x\" width=\"31\"/><span class=\"white ml-2\">U.S. Climate Data</span></a>\n",
      "Temperature - Precipitation - Sunshine - Snowfall\n",
      "\n",
      "<div class=\"float-left mb-4 mt-2\"><p class=\"selection_title\">Select a state by name</p></div>\n"
     ]
    }
   ],
   "source": [
    "#soup.p will give you the contents of the first paragraph tag on the page.\n",
    "#soup.a gives you anchors / links on the page.\n",
    "#Get contents of an attribute inside an HTML tag using square brackets and perentheses.\n",
    "#Use .parent to get the parent object, and .next_sibling to get the next peer object.\n",
    "#Use your browser's inspect element feature to find the tag for the data you want.\n",
    "print(soup.p)\n",
    "print(soup.p.text)\n",
    "print(soup.a)\n",
    "print(soup.a['title'])\n",
    "print()\n",
    "print(soup.p.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"float-left mb-4 mt-2\">\n",
      " <p class=\"selection_title\">\n",
      "  Select a state by name\n",
      " </p>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.p.parent.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "#\n",
      "/\n",
      "/climate/united-states/us\n",
      "/\n",
      "/climate/united-states/us\n",
      "/climate/alabama/united-states/3170\n",
      "/climate/alaska/united-states/3171\n",
      "/climate/arizona/united-states/3172\n",
      "/climate/arkansas/united-states/3173\n",
      "/climate/california/united-states/3174\n",
      "/climate/colorado/united-states/3175\n",
      "/climate/connecticut/united-states/3176\n",
      "/climate/delaware/united-states/3177\n",
      "/climate/district-of-columbia/united-states/3178\n",
      "/climate/florida/united-states/3179\n",
      "/climate/georgia/united-states/3180\n",
      "/climate/hawaii/united-states/3181\n",
      "/climate/idaho/united-states/3182\n",
      "/climate/illinois/united-states/3183\n",
      "/climate/indiana/united-states/3184\n",
      "/climate/iowa/united-states/3185\n",
      "/climate/kansas/united-states/3186\n",
      "/climate/kentucky/united-states/3187\n",
      "/climate/louisiana/united-states/3188\n",
      "/climate/maine/united-states/3189\n",
      "/climate/maryland/united-states/1872\n",
      "/climate/massachusetts/united-states/3191\n",
      "/climate/michigan/united-states/3192\n",
      "/climate/minnesota/united-states/3193\n",
      "/climate/mississippi/united-states/3194\n",
      "/climate/missouri/united-states/3195\n",
      "/climate/montana/united-states/919\n",
      "/climate/nebraska/united-states/3197\n",
      "/climate/nevada/united-states/3198\n",
      "/climate/new-hampshire/united-states/3199\n",
      "/climate/new-jersey/united-states/3200\n",
      "/climate/new-mexico/united-states/3201\n",
      "/climate/new-york/united-states/3202\n",
      "/climate/north-carolina/united-states/3203\n",
      "/climate/north-dakota/united-states/3204\n",
      "/climate/ohio/united-states/3205\n",
      "/climate/oklahoma/united-states/3206\n",
      "/climate/oregon/united-states/3207\n",
      "/climate/pennsylvania/united-states/3208\n",
      "/climate/puerto-rico/united-states/7335\n",
      "/climate/rhode-island/united-states/3209\n",
      "/climate/south-carolina/united-states/3210\n",
      "/climate/south-dakota/united-states/3211\n",
      "/climate/tennessee/united-states/3212\n",
      "/climate/texas/united-states/3213\n",
      "/climate/utah/united-states/3214\n",
      "/climate/vermont/united-states/3215\n",
      "/climate/virginia/united-states/3216\n",
      "/climate/washington/united-states/3217\n",
      "/climate/west-virginia/united-states/3218\n",
      "/climate/wisconsin/united-states/3219\n",
      "/climate/wyoming/united-states/3220\n",
      "/climate/washington/district-of-columbia/united-states/usdc0001\n",
      " https://facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus\n",
      "https://twitter.com/intent/tweet/?text=Climate United States - Normals and averages&url=https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus\n",
      "https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus&media=description=Climate United States - Normals and averages\n",
      "mailto:mail@example.com?subject=Climate United States - Normals and averages&body=Climate United States - Normals and averages - https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus\n",
      "https://www.tumblr.com/widgets/share/tool?posttype=link&title=Climate United States - Normals and averages&caption=&content=Climate United States - Normals and averages - https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus&canonicalUrl=https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus&shareSource=tumblr_share_button\n",
      "whatsapp://send?text='Climate United States - Normals and averages - https%3A%2F%2Fwww.usclimatedata.com%2Fclimate%2Funited-states%2Fus'\n",
      "https://www.facebook.com/yourweatherservice\n",
      "https://twitter.com/usclimatedata\n",
      "/website-info\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.usclimatedata.com'\n",
    "state_links = []\n",
    "for link in soup.find_all('a'):\n",
    "    url = link.get('href')\n",
    "    if url and '/climate/' in url and '/climate/united-states/us' not in url:\n",
    "        state_links.append(url)\n",
    "print(len(state_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate Colorado - Temperature, Rainfall and Averages\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(base_url + state_links[5])\n",
    "soup = BeautifulSoup(r.text)\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "rows = soup.find_all('tr')\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['46', '54', '61', '72', '82', '88', '79', '66', '52', '45']\n"
     ]
    }
   ],
   "source": [
    "rows = [row for row in rows if 'Average high' in str(row)]\n",
    "print(len(rows))\n",
    "\n",
    "high_temps = []\n",
    "for row in rows:\n",
    "    tds = row.find_all('td')\n",
    "    for i in range(1,6):\n",
    "        high_temps.append(tds[i].text)\n",
    "print(high_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorado\n",
      "Colorado\n"
     ]
    }
   ],
   "source": [
    "state = soup.title.string.split()[1]\n",
    "print(state)\n",
    "s = soup.title.string\n",
    "state = s[s.find(' '):s.find('-')].strip()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Colorado': ['46', '54', '61', '72', '82', '88', '79', '66', '52', '45']}\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data[state] = high_temps\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alabama': ['58', '67', '74', '82', '88', '91', '85', '75', '65', '56'], 'Alaska': ['27', '34', '44', '56', '63', '64', '55', '40', '28', '25'], 'Arizona': ['71', '77', '85', '95', '104', '104', '100', '89', '76', '66'], 'Arkansas': ['55', '64', '73', '81', '89', '93', '86', '75', '63', '52'], 'California': ['60', '65', '71', '80', '87', '91', '87', '78', '64', '54'], 'Colorado': ['46', '54', '61', '72', '82', '88', '79', '66', '52', '45'], 'Connecticut': ['40', '47', '58', '68', '77', '81', '74', '63', '53', '42'], 'Delaware': ['47', '55', '66', '75', '83', '85', '79', '69', '58', '47'], 'District Of Columbia': ['44', '53', '64', '75', '83', '84', '78', '67', '55', '45'], 'Florida': ['67', '74', '80', '87', '91', '92', '88', '81', '73', '65'], 'Georgia': ['57', '64', '72', '81', '86', '88', '82', '73', '64', '54'], 'Hawaii': ['80', '81', '83', '85', '87', '89', '89', '87', '84', '81'], 'Idaho': ['45', '55', '62', '72', '81', '90', '79', '65', '48', '38'], 'Illinois': ['36', '46', '59', '70', '81', '82', '75', '63', '48', '36'], 'Indiana': ['40', '51', '63', '73', '82', '83', '77', '65', '52', '39'], 'Iowa': ['36', '49', '62', '72', '82', '84', '76', '63', '48', '34'], 'Kansas': ['45', '56', '67', '76', '85', '89', '80', '68', '55', '42'], 'Kentucky': ['45', '55', '66', '75', '83', '86', '79', '68', '55', '44'], 'Louisiana': ['65', '72', '78', '85', '89', '91', '87', '80', '72', '64'], 'Maine': ['32', '40', '53', '65', '74', '78', '70', '57', '45', '33'], 'Maryland': ['46', '54', '65', '75', '85', '87', '80', '68', '58', '46'], 'Massachusetts': ['39', '45', '56', '66', '76', '80', '72', '61', '51', '41'], 'Michigan': ['33', '44', '58', '69', '78', '80', '73', '60', '47', '34'], 'Minnesota': ['31', '43', '58', '71', '80', '82', '73', '59', '42', '29'], 'Mississippi': ['60', '69', '76', '83', '89', '92', '87', '77', '67', '58'], 'Missouri': ['45', '56', '67', '75', '83', '88', '80', '69', '56', '43'], 'Montana': ['39', '48', '58', '67', '76', '85', '73', '59', '43', '32'], 'Nebraska': ['37', '50', '63', '73', '84', '86', '77', '64', '48', '36'], 'Nevada': ['50', '57', '63', '71', '81', '88', '80', '68', '54', '45'], 'New Hampshire': ['35', '44', '57', '69', '77', '81', '73', '60', '48', '36'], 'New Jersey': ['42', '51', '62', '72', '82', '84', '77', '65', '55', '44'], 'New Mexico': ['48', '56', '65', '74', '83', '83', '78', '67', '53', '43'], 'New York': ['42', '50', '60', '71', '79', '83', '76', '65', '54', '44'], 'North Carolina': ['55', '63', '72', '79', '86', '87', '81', '72', '62', '53'], 'North Dakota': ['28', '40', '57', '68', '77', '83', '72', '58', '40', '26'], 'Ohio': ['40', '52', '63', '73', '82', '84', '77', '65', '52', '41'], 'Oklahoma': ['55', '63', '72', '80', '88', '93', '85', '73', '62', '51'], 'Oregon': ['52', '56', '61', '68', '74', '82', '77', '64', '53', '46'], 'Pennsylvania': ['44', '53', '64', '74', '83', '85', '78', '67', '56', '45'], 'Puerto Rico': ['83', '83', '85', '86', '88', '88', '88', '87', '85', '83'], 'Rhode Island': ['40', '48', '59', '68', '78', '81', '74', '63', '53', '42'], 'South Carolina': ['63', '70', '76', '83', '88', '89', '85', '77', '70', '62'], 'South Dakota': ['27', '39', '57', '69', '78', '82', '72', '58', '39', '25'], 'Tennessee': ['55', '64', '73', '81', '89', '91', '85', '74', '63', '52'], 'Texas': ['65', '72', '80', '87', '92', '97', '91', '82', '71', '63'], 'Utah': ['44', '53', '61', '71', '82', '89', '78', '65', '50', '40'], 'Vermont': ['31', '40', '55', '67', '76', '79', '70', '57', '46', '33'], 'Virginia': ['51', '60', '70', '78', '86', '88', '81', '71', '61', '51'], 'Washington': ['44', '53', '64', '75', '83', '84', '78', '67', '55', '45'], 'West Virginia': ['47', '56', '68', '75', '82', '84', '78', '68', '57', '46'], 'Wisconsin': ['33', '42', '54', '65', '75', '78', '71', '59', '46', '33'], 'Wyoming': ['40', '47', '55', '65', '75', '81', '72', '59', '47', '38']}\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for state_link in state_links:\n",
    "    url = base_url + state_link\n",
    "    r = requests.get(base_url + state_link)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    rows = soup.find_all('tr')\n",
    "    rows = [row for row in rows if 'Average high' in str(row)]\n",
    "    high_temps = []\n",
    "    for row in rows:\n",
    "        tds = row.find_all('td')\n",
    "        for i in range(1,6):\n",
    "            high_temps.append(tds[i].text)\n",
    "    s = soup.title.string\n",
    "    state = s[s.find(' '):s.find('-')].strip()\n",
    "    data[state] = high_temps\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4bb0b42db137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.coingecko.com/en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\WebScrapeCrypto\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\WebScrapeCrypto\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m     return _parse(\n\u001b[0m\u001b[0;32m   1086\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[0mio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\WebScrapeCrypto\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[0mretained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\WebScrapeCrypto\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_LXML\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lxml not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_valid_parsers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfs = pd.read_html('https://www.coingecko.com/en', header=0)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('high_temps.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(data.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
